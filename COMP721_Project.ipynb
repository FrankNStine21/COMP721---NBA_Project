{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0mwjKcUj-oxT",
        "qCkY1vX4XNvz",
        "Sx7GU5ucjpN8",
        "lKcX0Hty-VDG",
        "OvWtI8PLWqhP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "COMP721 - Mini Project"
      ],
      "metadata": {
        "id": "67tQO2Q6Wh-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "216063593 - Benjamin Naidoo"
      ],
      "metadata": {
        "id": "eKlFzmvTXJcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "218015230 - Kailin Reddy"
      ],
      "metadata": {
        "id": "k83xJ33DXLlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All Imports"
      ],
      "metadata": {
        "id": "0mwjKcUj-oxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All Imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_absolute_error, explained_variance_score, max_error, mean_squared_error, median_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "_POB3ejG7FHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlier Detection - KNN"
      ],
      "metadata": {
        "id": "qCkY1vX4XNvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined Methods\n",
        "\n",
        "def perform_PCA(df):\n",
        "    x = StandardScaler().fit_transform(df)\n",
        "    pca = PCA(n_components=2)\n",
        "    principalComponents = pca.fit_transform(x)\n",
        "    principalDf = pd.DataFrame(data=principalComponents, columns=['principal component 1', 'principal component 2'])\n",
        "    return principalDf\n",
        "\n",
        "def outlierDetect(df1, year, start, end, name):\n",
        "    df = df1.iloc[:, start:end].fillna(0)\n",
        "\n",
        "    principalDf = perform_PCA(df)\n",
        "    X = principalDf.values\n",
        "\n",
        "    nbrs = NearestNeighbors(n_neighbors=3)\n",
        "    nbrs.fit(X)\n",
        "    # distances and indexes of k-neighbors from model outputs\n",
        "    distances, indexes = nbrs.kneighbors(X)  \n",
        "    # plot mean of k-distances of each observation\n",
        "\n",
        "    player_playoffs_outlier_index = np.where(distances.mean(axis=1) > 1)\n",
        "\n",
        "    startIndex = df.index[0]\n",
        "    updatedOutlierIndices = []\n",
        "    for i in range(len(player_playoffs_outlier_index[0])):\n",
        "        updatedOutlierIndices.append(player_playoffs_outlier_index[0][i] + startIndex)\n",
        "\n",
        "    outlier_values = principalDf.iloc[player_playoffs_outlier_index]\n",
        "    Y = df1.iloc[player_playoffs_outlier_index]\n",
        "\n",
        "    data_with_clusters = Y.copy()\n",
        "    data_with_clusters['PrincipalComponent1'] = 0.0\n",
        "    data_with_clusters['PrincipalComponent2'] = 0.0\n",
        "\n",
        "    for i in range(len(updatedOutlierIndices)):\n",
        "        data_with_clusters['PrincipalComponent1'][updatedOutlierIndices[i]] = principalDf['principal component 1'][player_playoffs_outlier_index[0][i]]\n",
        "        data_with_clusters['PrincipalComponent2'][updatedOutlierIndices[i]] = principalDf['principal component 2'][player_playoffs_outlier_index[0][i]]\n",
        "\n",
        "    indexArray = []\n",
        "    count = 0\n",
        "\n",
        "    for index in updatedOutlierIndices:\n",
        "        for out in outlier_values[\"principal component 1\"]:\n",
        "            if (data_with_clusters['PrincipalComponent1'][index] == out):\n",
        "                indexArray.append(index)\n",
        "        count = count + 1\n",
        "\n",
        "    indexArray2 = []\n",
        "    count = 0\n",
        "\n",
        "    for index in updatedOutlierIndices:\n",
        "        for out in outlier_values[\"principal component 2\"]:\n",
        "            if (data_with_clusters['PrincipalComponent2'][index] == out):\n",
        "                indexArray2.append(index)\n",
        "        count = count + 1\n",
        "\n",
        "    finalIndexArray = []\n",
        "\n",
        "    for m in indexArray:\n",
        "        for n in indexArray2:\n",
        "            if (m == n):\n",
        "                finalIndexArray.append(m)\n",
        "\n",
        "    if (year < 0):\n",
        "        print('The Outstanding players for ' + name + ' are : ')\n",
        "    else:\n",
        "        print('The Outstanding players for ' + name + ' in the year ' + str(year) + ' are : ')\n",
        "    print('================================================================================')\n",
        "    for i in finalIndexArray:\n",
        "        print(data_with_clusters['firstname'][i] + ' ' + data_with_clusters['lastname'][i])\n",
        "\n",
        "    print(\"===============================================================================\")\n",
        "\n",
        "    # plot outlier values\n",
        "    plt.scatter(principalDf[\"principal component 1\"], principalDf[\"principal component 2\"], color=\"gray\",)\n",
        "    plt.scatter(outlier_values[\"principal component 1\"], outlier_values[\"principal component 2\"], color=\"red\")\n",
        "    plt.show()\n",
        "\n",
        "def readPlayerFiles(filename, start, end, name):\n",
        "    df = pd.read_csv(filename, header=0).fillna(0)\n",
        "\n",
        "\n",
        "    if \"year\" in df.columns:\n",
        "        df1 = df.sort_values(by='year')\n",
        "        df1 = df1.reset_index(drop=True)\n",
        "\n",
        "        dataFrameArr = []\n",
        "        years = []\n",
        "        for year in df1[\"year\"]:\n",
        "            if (year not in years):\n",
        "                years.append(year)\n",
        "\n",
        "        for year in years:\n",
        "            newDataFrame = df1.query(\"year==\" + str(year))\n",
        "            dataFrameArr.append(newDataFrame)\n",
        "\n",
        "        for i in range(len(dataFrameArr)):\n",
        "            newOutlier = dataFrameArr[i]\n",
        "            outlierDetect(newOutlier, years[i], start, end, name)\n",
        "            print()\n",
        "            print()\n",
        "\n",
        "    else:\n",
        "        outlierDetect(df, -1, start, end, name)\n",
        "        print()\n",
        "        print()"
      ],
      "metadata": {
        "id": "GPelKHR5ooPk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlier Detection - KMeans"
      ],
      "metadata": {
        "id": "Sx7GU5ucjpN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined Methods\n",
        "\n",
        "def perform_PCA(df):\n",
        "    x = StandardScaler().fit_transform(df)\n",
        "    pca = PCA(n_components=2)\n",
        "    principalComponents = pca.fit_transform(x)\n",
        "    principalDf = pd.DataFrame(data=principalComponents, columns=['principal component 1', 'principal component 2'])\n",
        "    return principalDf\n",
        "\n",
        "\n",
        "def get_Dist(x1, y1, x2, y2):\n",
        "    diffX = x2 - x1\n",
        "    diffY = y2 - y1\n",
        "    if diffX <= 0 and diffY <= 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return math.sqrt(math.pow(x2 - x1, 2) + math.pow(y2 - y1, 2))\n",
        "\n",
        "\n",
        "def outlierDetect(df, year, start, end, name):\n",
        "    df1 = df.iloc[:, start:end]\n",
        "\n",
        "    principalDF = perform_PCA(df1)\n",
        "\n",
        "    model = KMeans(n_clusters=1, random_state=0)\n",
        "    identified_clusters = model.fit(principalDF[['principal component 1', 'principal component 2']])\n",
        "    clusterCenter = model.cluster_centers_[0]\n",
        "    x1 = clusterCenter[0]\n",
        "    y1 = clusterCenter[1]\n",
        "\n",
        "    identified_clusters1 = identified_clusters.predict(principalDF[['principal component 1', 'principal component 2']])\n",
        "\n",
        "    data_with_clusters = df.copy()\n",
        "\n",
        "    data_with_clusters['Clusters'] = identified_clusters1\n",
        "    data_with_clusters['PC1'] = 0.0\n",
        "    data_with_clusters['PC2'] = 0.0\n",
        "    startIndex = data_with_clusters.index[0]\n",
        "\n",
        "    for i in range(len(data_with_clusters['firstname'])):\n",
        "        data_with_clusters['PC1'][i + startIndex] = principalDF['principal component 1'][i]\n",
        "        data_with_clusters['PC2'][i + startIndex] = principalDF['principal component 2'][i]\n",
        "\n",
        "    data_with_clusters['distFromCentre'] = 0.0\n",
        "\n",
        "    for i in range(len(data_with_clusters['PC1'])):\n",
        "        data_with_clusters['distFromCentre'][i + startIndex] = get_Dist(x1, y1, data_with_clusters[\"PC1\"][i + startIndex], data_with_clusters['PC2'][i + startIndex])\n",
        "\n",
        "    thresh1 = (max(data_with_clusters[\"PC1\"]) + max(data_with_clusters[\"PC2\"])) / 2\n",
        "    df = data_with_clusters.query(\"distFromCentre > \" + str(thresh1))\n",
        "\n",
        "    if (year < 0):\n",
        "        print('The Outstanding players for ' + name + ' are : ')\n",
        "    else:\n",
        "        print('The Outstanding players for ' + name + ' in the year ' + str(year) + ' are : ')\n",
        "\n",
        "    print('================================================================================')\n",
        "\n",
        "    for i in df.index:\n",
        "        print(df['firstname'][i] + ' ' + df['lastname'][i])\n",
        "\n",
        "    print(\"================================================================================\")\n",
        "\n",
        "    plt.scatter(principalDF['principal component 1'], principalDF['principal component 2'], color='gray')\n",
        "    plt.scatter(df['PC1'], df['PC2'], color='red')\n",
        "    plt.show()\n",
        "\n",
        "def readPlayerFiles(filename, start, end, name):\n",
        "    df = pd.read_csv(filename, header=0).fillna(0)\n",
        "\n",
        "    if \"year\" in df.columns:\n",
        "        df1 = df.sort_values(by='year')\n",
        "        df1 = df1.reset_index(drop=True)\n",
        "\n",
        "        dataFrameArr = []\n",
        "        years = []\n",
        "        for year in df1[\"year\"]:\n",
        "            if (year not in years):\n",
        "                years.append(year)\n",
        "\n",
        "        for year in years:\n",
        "            newDataFrame = df1.query(\"year==\" + str(year))\n",
        "            dataFrameArr.append(newDataFrame)\n",
        "\n",
        "        for i in range(len(dataFrameArr)):\n",
        "            newOutlier = dataFrameArr[i]\n",
        "            outlierDetect(newOutlier, years[i], start, end, name)\n",
        "            print()\n",
        "            print()\n",
        "\n",
        "\n",
        "    else:\n",
        "        outlierDetect(df, -1, start, end, name)\n",
        "        print()\n",
        "        print()"
      ],
      "metadata": {
        "id": "-i6RY2NwjuD8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Outlier Detection"
      ],
      "metadata": {
        "id": "lKcX0Hty-VDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running code\n",
        "# Run either KNN or KMeans block to define methods before running this block\n",
        "\n",
        "readPlayerFiles(\"/content/drive/MyDrive/Colab Notebooks/Data/player_regular_season_career.txt\", 8, 23, \"NBA Regular Seasons in general\")\n",
        "print(\"===================================================================\")\n",
        "\n",
        "readPlayerFiles(\"/content/drive/MyDrive/Colab Notebooks/Data/player_playoffs_career.txt\", 8, 21, \"NBA Playoffs in General\")\n",
        "print(\"===================================================================\")\n",
        "\n",
        "readPlayerFiles(\"/content/drive/MyDrive/Colab Notebooks/Data/player_regular_season.txt\", 6, 23, \"NBA Regular Seasons\")\n",
        "print(\"===================================================================\")\n",
        "\n",
        "readPlayerFiles(\"/content/drive/MyDrive/Colab Notebooks/Data/player_playoffs.txt\", 8, 23, \"NBA Playoffs\")\n",
        "print(\"===================================================================\")\n",
        "\n",
        "readPlayerFiles(\"/content/drive/MyDrive/Colab Notebooks/Data/player_allstar.txt\", 8, 23, \"NBA All Star\")"
      ],
      "metadata": {
        "id": "q2YTy1kr-WeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Game Outcome Prediction"
      ],
      "metadata": {
        "id": "OvWtI8PLWqhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined Methods\n",
        "def get_win_rate(teamSeasonRow):\n",
        "\t\treturn teamSeasonRow[\"won\"] / (teamSeasonRow[\"won\"] + teamSeasonRow[\"lost\"])\n",
        "  \n",
        "def get_o_3pm_value(teamSeasonRow):\n",
        "\t\tteamSeasonWinRate = get_win_rate(teamSeasonRow)\n",
        "\t\tif teamSeasonRow[\"year\"] < 1979:\n",
        "\t\t\to_3pmMultiplier = 1 + ((teamSeasonWinRate - averageWinRate) / averageWinRate)\n",
        "\t\t\treturn int(round(o_3pmAverage * o_3pmMultiplier, ndigits=0))\n",
        "\t\telse:\n",
        "\t\t\treturn teamSeasonRow[\"o_3pm\"]\n",
        "\n",
        "def get_d_3pm_value(teamSeasonRow):\n",
        "\t\tteamSeasonWinRate = get_win_rate(teamSeasonRow)\n",
        "\t\tif teamSeasonRow[\"year\"] < 1979:\n",
        "\t\t\td_3pmMultiplier = 1 + ((teamSeasonWinRate - averageWinRate) / averageWinRate)\n",
        "\t\t\treturn int(round(d_3pmAverage * d_3pmMultiplier, ndigits=0))\n",
        "\t\telse:\n",
        "\t\t\treturn teamSeasonRow[\"d_3pm\"]\n",
        "\n",
        "def get_o_3pa_value(teamSeasonRow):\n",
        "\t\tif teamSeasonRow[\"year\"] < 1999:\n",
        "\t\t\treturn int(round(teamSeasonRow[\"o_3pm\"] * o_3paMultiplier, ndigits=0))\n",
        "\t\telse:\n",
        "\t\t\treturn teamSeasonRow[\"o_3pa\"]\n",
        "\n",
        "def get_d_3pa_value(teamSeasonRow):\n",
        "\t\tif teamSeasonRow[\"year\"] < 1999:\n",
        "\t\t\treturn int(round(teamSeasonRow[\"d_3pm\"] * d_3paMultiplier, ndigits=0))\n",
        "\t\telse:\n",
        "\t\t\treturn teamSeasonRow[\"d_3pa\"]"
      ],
      "metadata": {
        "id": "ePzyX294WNC8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "teamSeasonDF = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/team_season.txt\", header=0)\n",
        "teamSeasonDF.drop(teamSeasonDF[teamSeasonDF.year < 1976].index, inplace=True)\n",
        "teamSeasonDF.reset_index(inplace=True, drop=True) \n",
        "\n",
        "# Model Training\n",
        "labelsDF = pd.DataFrame(columns=[\"win_rate\"])\n",
        "labelsDF[\"win_rate\"] = teamSeasonDF.apply(get_win_rate, axis=1)\n",
        "\n",
        "averageWinRate = teamSeasonDF[\"won\"].sum() / (teamSeasonDF[\"won\"].sum() + teamSeasonDF[\"lost\"].sum())\n",
        "\n",
        "teamSeason1979DF = teamSeasonDF[teamSeasonDF.year >= 1979]\n",
        "\n",
        "o_3pmDF = teamSeason1979DF[\"o_3pm\"]\n",
        "o_3pmAverage = o_3pmDF.sum() / len(teamSeason1979DF.index)\n",
        "\n",
        "d_3pmDF = teamSeason1979DF[\"d_3pm\"]\n",
        "d_3pmAverage = d_3pmDF.sum() / len(teamSeason1979DF.index)\n",
        "\n",
        "teamSeasonDF[\"o_3pm\"] = teamSeasonDF.apply(get_o_3pm_value, axis=1)\n",
        "teamSeasonDF[\"d_3pm\"] = teamSeasonDF.apply(get_d_3pm_value, axis=1)\n",
        "\n",
        "teamSeason1999DF = teamSeasonDF[teamSeasonDF.year >= 1999]\n",
        "\n",
        "o_3pmDF = teamSeason1999DF[\"o_3pm\"]\n",
        "o_3paDF = teamSeason1999DF[\"o_3pa\"]\n",
        "o_3paMultiplier = o_3paDF.sum() / o_3pmDF.sum()\n",
        "\n",
        "d_3pmDF = teamSeason1999DF[\"d_3pm\"]\n",
        "d_3paDF = teamSeason1999DF[\"d_3pa\"]\n",
        "d_3paMultiplier = d_3paDF.sum() / d_3pmDF.sum()\n",
        "\n",
        "teamSeasonDF[\"o_3pa\"] = teamSeasonDF.apply(get_o_3pa_value, axis=1)\n",
        "teamSeasonDF[\"d_3pa\"] = teamSeasonDF.apply(get_d_3pa_value, axis=1)\n",
        "\n",
        "# Create dataframe with only required features\n",
        "featureMatrixDF = teamSeasonDF.drop([\"team\", \"year\", \"leag\", \"won\", \"lost\"], axis=1)\n",
        "\n",
        "featuresTrain, featuresTest, labelsTrain, labelsTest = train_test_split(featureMatrixDF, labelsDF, train_size=0.80, random_state=1)\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(featuresTrain)\n",
        "\n",
        "featuresTrainNormalised = pd.DataFrame(scaler.transform(featuresTrain), columns=featuresTrain.columns)\n",
        "featuresTestNormalised = pd.DataFrame(scaler.transform(featuresTest), columns=featuresTest.columns)\n",
        "\n",
        "mlpRegressor = MLPRegressor(hidden_layer_sizes=(100, 100, 100), solver=\"lbfgs\", activation=\"tanh\", random_state=1, max_iter=10000)\n",
        "svRegressor = SVR()\n",
        "\n",
        "for algorithm in [mlpRegressor, svRegressor]:\n",
        "\t\tprint(\"Algorithm:\", algorithm.__class__.__name__)\n",
        "\t\tprint()\n",
        "\t\talgorithm.fit(featuresTrainNormalised, np.ravel(labelsTrain))\n",
        "\t\tlabelPredictions = algorithm.predict(featuresTestNormalised)\n",
        "\t\tprint(\"\\tPrediction Metrics:\")\n",
        "\t\tprint(\"\\t\\tMax Error: \", round(max_error(labelsTest, labelPredictions), 3))\n",
        "\t\tprint(\"\\t\\tExplained Variance Score: \", round(explained_variance_score(labelsTest, labelPredictions), 3))\n",
        "\t\tprint(\"\\t\\tMean Absolute Error: \", round(mean_absolute_error(labelsTest, labelPredictions), 3))\n",
        "\t\tprint(\"\\t\\tMean Squared Error: \", round(mean_squared_error(labelsTest, labelPredictions), 3))\n",
        "\t\tprint(\"\\t\\tMedian Absolute Error: \", round(median_absolute_error(labelsTest, labelPredictions), 3))\n",
        "\t\tprint(\"\\t\\tR2 Score: \", round(r2_score(labelsTest, labelPredictions), 3))\n",
        "\t\tprint()"
      ],
      "metadata": {
        "id": "8-6uFCdiXFE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load teams.txt\n",
        "teamsFile = \"/content/drive/MyDrive/Colab Notebooks/Data/teams.txt\"\n",
        "teamsDF = pd.read_csv(teamsFile)\n",
        "print(teamsDF.head())"
      ],
      "metadata": {
        "id": "dPSHJgHky1UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose 2 teams for comparison\n",
        "compareDF = teamSeasonDF.sample(n=2)\n",
        "print(compareDF)"
      ],
      "metadata": {
        "id": "gkLsDep94qJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display teams for comparison\n",
        "team1Label = compareDF.iloc[0, 0]\n",
        "team1year = compareDF.iloc[0, 1]\n",
        "\n",
        "team2Label = compareDF.iloc[1, 0]\n",
        "team2year = compareDF.iloc[1, 1]\n",
        "\n",
        "team1row = teamsDF.loc[teamsDF['team']==team1Label]\n",
        "team1 = \"Team 1 : \" + str(team1row.iloc[0, 1]) + \" \" + str(team1row.iloc[0, 2])\n",
        "print(team1)\n",
        "print(\"Year : \", team1year)\n",
        "print()\n",
        "\n",
        "team2row = teamsDF.loc[teamsDF['team']==team2Label]\n",
        "team2 = \"Team 2 : \" + str(team2row.iloc[0, 1]) + \" \" + str(team2row.iloc[0, 2])\n",
        "print(team2)\n",
        "print(\"Year : \", team2year)\n",
        "\n",
        "compareDF = compareDF.drop(['won', 'lost', 'year', 'leag', 'team'], axis=1)"
      ],
      "metadata": {
        "id": "moSKlripLZBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "print(\"Model - MLP Regression\")\n",
        "print()\n",
        "\n",
        "winProbability = mlpRegressor.predict(compareDF)\n",
        "winProbT1 = winProbability[0]\n",
        "winProbT2 = winProbability[1]\n",
        "\n",
        "print(\"Win Probability of Team 1: \", winProbT1)\n",
        "print(\"Win Probability of Team 2: \", winProbT2)\n",
        "print()\n",
        "\n",
        "# Normalization\n",
        "normWinProbT1 = winProbT1 / (winProbT1 + winProbT2)\n",
        "normWinProbT2 = winProbT2 / (winProbT1 + winProbT2)\n",
        "\n",
        "print(\"The probability of Team 1 beating Team 2 is: \", normWinProbT1)\n",
        "print(\"The probability of Team 2 beating Team 1 is: \", normWinProbT2)\n",
        "\n",
        "if (normWinProbT1 > normWinProbT2) :\n",
        "  winner = team1\n",
        "else :\n",
        "  winner = team2\n",
        "\n",
        "print()\n",
        "print(\"The winner is \", winner)"
      ],
      "metadata": {
        "id": "3kVSYEeahzHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}